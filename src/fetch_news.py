#!/usr/bin/env python3
"""
Fetch AI/Tech news using RSS feeds and summarize with Claude.
"""

import anthropic
import feedparser
import json
import os
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed

# AI/Tech RSS feeds from authoritative sources
RSS_FEEDS = [
    # ===== AI/ç§‘æŠ€ä¸“ä¸šåª’ä½“ (è‹±æ–‡) =====
    "https://techcrunch.com/feed/",
    "https://www.theverge.com/rss/index.xml",
    "https://feeds.arstechnica.com/arstechnica/technology-lab",
    "https://www.wired.com/feed/rss",
    "https://venturebeat.com/feed/",
    "https://www.technologyreview.com/feed/",
    "https://feeds.feedburner.com/TechCrunch/artificial-intelligence",
    # AI å…¬å¸å®˜æ–¹åšå®¢
    "https://openai.com/blog/rss.xml",
    "https://blog.google/technology/ai/rss/",
    "https://ai.meta.com/blog/rss/",
    "https://www.anthropic.com/rss.xml",
    # æŠ€æœ¯ç¤¾åŒº
    "https://hnrss.org/frontpage",  # Hacker News
    "https://www.reddit.com/r/MachineLearning/.rss",
    "https://www.reddit.com/r/artificial/.rss",

    # ===== ä¸­æ–‡ç§‘æŠ€åª’ä½“ =====
    "https://36kr.com/feed",
    "https://www.jiqizhixin.com/rss",  # æœºå™¨ä¹‹å¿ƒ
    "https://www.leiphone.com/feed",   # é›·é”‹ç½‘
    "https://www.huxiu.com/rss/0.xml", # è™å—…
    "https://www.tmtpost.com/feed",    # é’›åª’ä½“
    "https://www.pingwest.com/feed",   # PingWestå“ç©
    "https://www.ifanr.com/feed",      # çˆ±èŒƒå„¿
    "https://sspai.com/feed",          # å°‘æ•°æ´¾
    "https://www.geekpark.net/rss",    # æå®¢å…¬å›­

    # ===== å›½é™…ä¸»æµåª’ä½“ç§‘æŠ€é¢‘é“ =====
    "https://feeds.reuters.com/reuters/technologyNews",
    "https://feeds.bbci.co.uk/news/technology/rss.xml",
    "http://rss.cnn.com/rss/cnn_tech.rss",
    "https://www.cnbc.com/id/19854910/device/rss/rss.html",  # CNBC Tech
    "https://feeds.bloomberg.com/technology/news.rss",
    "https://www.ft.com/technology?format=rss",  # Financial Times Tech

    # ===== Bç«™ UPä¸» (é€šè¿‡ RSSHub) =====
    "https://rsshub.app/bilibili/user/video/612932327",   # è€çŸ³è°ˆèŠ¯ (ç¡¬ä»¶/èŠ¯ç‰‡)
    "https://rsshub.app/bilibili/user/video/266765166",   # æ¼«å£«æ²‰æ€å½• (AI/æ•°å­¦ç§‘æ™®)
    "https://rsshub.app/bilibili/user/video/517221395",   # ZOMIé…± (AIç³»ç»Ÿ/æ¡†æ¶)
    "https://rsshub.app/bilibili/user/video/504715181",   # ç‹æœ¨å¤´å­¦ç§‘å­¦ (æ·±åº¦å­¦ä¹ )

    # ===== æ’­å®¢ (é€šè¿‡ RSSHub æˆ–å®˜æ–¹ RSS) =====
    "https://rsshub.app/ximalaya/album/51487187",         # ç¡…è°·101
    "https://rsshub.app/ximalaya/album/29161862",         # OnBoard!
    "https://rsshub.app/ximalaya/album/3558668",          # 42ç« ç»

    # ===== æŠ€æœ¯åšå®¢/Newsletter =====
    "https://github.blog/feed/",                          # GitHub Blog
    "https://a16z.com/feed/",                             # a16z (Andreessen Horowitz)

    # ===== å¾®ä¿¡å…¬ä¼—å· (é€šè¿‡ç¬¬ä¸‰æ–¹ RSS æœåŠ¡) =====
    # -- å·²æ‰¾åˆ° RSS çš„å…¬ä¼—å· --
    "https://wechat2rss.xlab.app/feed/a1cd365aa14ed7d64cabfc8aa086da40ecaba34d.xml",  # å¤•å°ç‘¶ç§‘æŠ€è¯´
    "https://wechat2rss.xlab.app/feed/9685937b45fe9c7a526dbc32e4f24ba879a65b9a.xml",  # è…¾è®¯æŠ€æœ¯å·¥ç¨‹
    "https://feed.hamibot.com/api/feeds/6131b5301269c358aa0dec25",  # ç™½é²¸å‡ºæµ·
    "https://feed.hamibot.com/api/feeds/6121d8a451e2511a8279faaf",  # æ™šç‚¹LatePost
    "https://feed.hamibot.com/api/feeds/613570931269c358aa0f0cca",  # æµ·å¤–ç‹¬è§’å…½

    # ===== ç‹¬ç«‹åšå®¢/ç½‘ç«™ =====
    "https://baoyu.io/feed.xml",                                    # å®ç‰AI
    "https://www.latepost.com/rss",                                 # æ™šç‚¹LatePostå®˜ç½‘

    # ===== å¾…æ·»åŠ çš„å…¬ä¼—å· =====
    # ä»¥ä¸‹å…¬ä¼—å·æš‚æ— å…¬å¼€ RSSï¼Œéœ€è¦é€šè¿‡ WeWe RSS (åŸºäºå¾®ä¿¡è¯»ä¹¦) è‡ªå»ºè·å–ï¼š
    # https://github.com/cooderl/wewe-rss
    #
    # è…¾è®¯ç ”ç©¶é™¢ã€AGI Huntã€è…¾è®¯ç§‘æŠ€ã€Web3å¤©ç©ºä¹‹åŸã€è€åˆ˜è¯´NLPã€
    # founder parkã€AIç‚¼é‡‘æœ¯ã€åå­—è·¯å£crossingã€å½’è—çš„AIå·¥å…·ç®±
    #
    # è·å–åˆ° RSS é“¾æ¥åï¼Œåœ¨æ­¤å¤„æ·»åŠ å³å¯ã€‚
]

def get_time_window(send_hour: int = 18) -> tuple[str, str]:
    """Calculate the news time window based on send time."""
    now = datetime.now()
    end_time = now.replace(hour=send_hour, minute=0, second=0, microsecond=0)

    if now.hour < send_hour:
        end_time = end_time - timedelta(days=1)

    start_time = end_time - timedelta(days=1)

    return (
        start_time.strftime("%Y-%m-%d %H:%M"),
        (end_time - timedelta(minutes=1)).strftime("%Y-%m-%d %H:%M")
    )

def parse_feed(feed_url: str, hours_ago: int = 24) -> list[dict]:
    """Parse a single RSS feed and return recent articles."""
    articles = []
    cutoff_time = datetime.now() - timedelta(hours=hours_ago)

    try:
        feed = feedparser.parse(feed_url)
        source_name = feed.feed.get("title", feed_url)

        for entry in feed.entries[:20]:  # Limit entries per feed
            # Parse published time
            published = None
            if hasattr(entry, "published_parsed") and entry.published_parsed:
                published = datetime(*entry.published_parsed[:6])
            elif hasattr(entry, "updated_parsed") and entry.updated_parsed:
                published = datetime(*entry.updated_parsed[:6])

            # Skip if too old or no date
            if published and published < cutoff_time:
                continue

            articles.append({
                "title": entry.get("title", ""),
                "description": entry.get("summary", entry.get("description", ""))[:500],
                "source": source_name,
                "url": entry.get("link", ""),
                "published": published.isoformat() if published else ""
            })
    except Exception as e:
        print(f"  Warning: Failed to parse {feed_url}: {e}")

    return articles

def fetch_raw_news(hours_ago: int = 24) -> list[dict]:
    """Fetch raw news from multiple RSS feeds in parallel."""
    all_articles = []

    with ThreadPoolExecutor(max_workers=10) as executor:
        futures = {executor.submit(parse_feed, url, hours_ago): url for url in RSS_FEEDS}

        for future in as_completed(futures):
            try:
                articles = future.result()
                all_articles.extend(articles)
            except Exception as e:
                print(f"  Warning: Feed error: {e}")

    # Sort by published time (newest first)
    all_articles.sort(key=lambda x: x.get("published", ""), reverse=True)

    return all_articles

CATEGORIES = [
    {"name": "æŠ€æœ¯è¿›å±•", "icon": "ğŸ”¬"},
    {"name": "äº§å“å‘å¸ƒ", "icon": "ğŸš€"},
    {"name": "æŠ•èèµ„", "icon": "ğŸ’°"},
    {"name": "å·¨å¤´åŠ¨å‘", "icon": "ğŸ¢"},
    {"name": "è¡Œä¸šè§‚å¯Ÿ", "icon": "ğŸ“Š"},
    {"name": "å¼€æºä¸å¼€å‘è€…", "icon": "ğŸ‘¨â€ğŸ’»"},
]

def summarize_news_with_claude(anthropic_key: str, articles: list[dict], max_items: int = 10) -> list[dict]:
    """Use Claude to summarize, categorize, and select top news."""

    if not articles:
        return []

    client = anthropic.Anthropic(api_key=anthropic_key)

    # Prepare articles for Claude
    articles_text = ""
    for i, article in enumerate(articles[:50], 1):  # Limit to 50 articles
        articles_text += f"""
---
Article {i}:
Title: {article.get('title', '')}
Source: {article.get('source', '')}
Published: {article.get('published', '')}
Description: {article.get('description', '')}
URL: {article.get('url', '')}
"""

    category_names = "ã€".join(c["name"] for c in CATEGORIES)
    category_json_example = json.dumps(
        [{"name": c["name"], "icon": c["icon"], "news": [{"title": "...", "summary": "...", "source": "...", "url": "..."}]} for c in CATEGORIES[:2]],
        ensure_ascii=False, indent=4
    )

    prompt = f"""ä»¥ä¸‹æ˜¯æœ€è¿‘24å°æ—¶å†…çš„ AI/ç§‘æŠ€æ–°é—»åˆ—è¡¨ã€‚è¯·å¸®æˆ‘ï¼š

1. ç­›é€‰å‡ºæœ€é‡è¦ã€æœ€å€¼å¾—å…³æ³¨çš„æ–°é—»ï¼ˆæœ€å¤š {max_items} æ¡ï¼‰
2. å»é‡ï¼šç›¸åŒäº‹ä»¶çš„å¤šç¯‡æŠ¥é“åªä¿ç•™ä¸€æ¡ï¼ˆä¿ç•™æœ€æƒå¨æ¥æºï¼‰
3. æŒ‰é‡è¦æ€§æ’åºï¼ˆå…¨çƒå½±å“ > è¡Œä¸šå½±å“ > åŒºåŸŸå½±å“ï¼‰
4. ä¸ºæ¯æ¡æ–°é—»å†™ä¸€ä¸ªç®€çŸ­çš„ä¸­æ–‡æ‘˜è¦ï¼ˆ1-2å¥è¯ï¼‰
5. å°†æ–°é—»æŒ‰ä»¥ä¸‹ç±»åˆ«åˆ†ç»„ï¼š{category_names}
   - æ¯æ¡æ–°é—»åªå½’å…¥ä¸€ä¸ªæœ€åŒ¹é…çš„ç±»åˆ«
   - æ²¡æœ‰å¯¹åº”æ–°é—»çš„ç±»åˆ«ä¸è¦è¾“å‡º

é‡è¦ï¼šæ‘˜è¦å’Œæ ‡é¢˜ä¸­ä¸è¦ä½¿ç”¨åŒå¼•å·ï¼Œç”¨å•å¼•å·æˆ–å…¶ä»–æ ‡ç‚¹ä»£æ›¿ã€‚

æ–°é—»åˆ—è¡¨ï¼š
{articles_text}

è¯·ä»¥ JSON æ ¼å¼è¿”å›ï¼Œç»“æ„å¦‚ä¸‹ï¼š
{{
  "categories": {category_json_example}
}}

æ³¨æ„ï¼š
- åªè¿”å›æœ‰æ–°é—»çš„ç±»åˆ«
- icon å¿…é¡»ä¸ç±»åˆ«å¯¹åº”ï¼ˆæŠ€æœ¯è¿›å±•:ğŸ”¬ äº§å“å‘å¸ƒ:ğŸš€ æŠ•èèµ„:ğŸ’° å·¨å¤´åŠ¨å‘:ğŸ¢ è¡Œä¸šè§‚å¯Ÿ:ğŸ“Š å¼€æºä¸å¼€å‘è€…:ğŸ‘¨â€ğŸ’»ï¼‰
- åªè¿”å›åˆæ³•çš„ JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—
- ç¡®ä¿æ‰€æœ‰å­—ç¬¦ä¸²ä¸­çš„åŒå¼•å·ç”¨å•å¼•å·æ›¿æ¢"""

    try:
        response = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=4096,
            messages=[{"role": "user", "content": prompt}]
        )

        response_text = response.content[0].text

        # Extract JSON from response
        start_idx = response_text.find('{')
        end_idx = response_text.rfind('}') + 1
        if start_idx != -1 and end_idx > start_idx:
            json_str = response_text[start_idx:end_idx]
            try:
                result = json.loads(json_str)
            except json.JSONDecodeError:
                # Fix common JSON issues: unescaped quotes in values
                import re
                # Remove control characters
                json_str = re.sub(r'[\x00-\x1f\x7f]', ' ', json_str)
                json_str = json_str.replace('\\"', '"')  # normalize
                lines = json_str.split('\n')
                fixed_lines = []
                for line in lines:
                    m = re.match(r'^(\s*"(?:title|summary|source|url|name|icon)":\s*")(.*)(",?\s*)$', line)
                    if m:
                        value = m.group(2).replace('"', "'")
                        line = m.group(1) + value + m.group(3)
                    fixed_lines.append(line)
                json_str = '\n'.join(fixed_lines)
                result = json.loads(json_str)
            return result.get("categories", [])
    except Exception as e:
        print(f"  Error: Failed to summarize news: {e}")

    return []

def fetch_news(anthropic_key: str, topic: str = "AI/ç§‘æŠ€", max_items: int = 10) -> dict:
    """Fetch and process news."""

    today = datetime.now().strftime("%Y-%m-%d")
    start_time, end_time = get_time_window(18)

    print("  - Fetching news from RSS feeds...")
    raw_articles = fetch_raw_news(hours_ago=24)
    print(f"  - Got {len(raw_articles)} raw articles")

    if not raw_articles:
        return {
            "date": today,
            "time_window": f"{start_time} ~ {end_time}",
            "categories": [],
            "error": "No articles fetched from RSS feeds"
        }

    print("  - Summarizing with Claude...")
    categories = summarize_news_with_claude(anthropic_key, raw_articles, max_items)
    total = sum(len(c.get("news", [])) for c in categories)
    print(f"  - Selected {total} top news in {len(categories)} categories")

    return {
        "date": today,
        "time_window": f"{start_time} ~ {end_time}",
        "categories": categories
    }

def format_email_html(news_data: dict) -> str:
    """Format news data into a beautiful HTML email."""
    date = news_data.get("date", "")
    time_window = news_data.get("time_window", "")
    categories = news_data.get("categories", [])

    # Build category sections
    sections_html = ""
    if not categories:
        sections_html = '<tr><td style="padding:20px 30px;color:#666;font-size:16px;">ä»Šæ—¥æš‚æ— é‡è¦æ–°é—»ã€‚</td></tr>'
    else:
        for cat in categories:
            icon = cat.get("icon", "ğŸ“°")
            name = cat.get("name", "")
            news_items = cat.get("news", [])

            cards_html = ""
            for item in news_items:
                title = item.get("title", "")
                summary = item.get("summary", "")
                source = item.get("source", "")
                url = item.get("url", "#")

                cards_html += f'''<table width="100%" cellpadding="0" cellspacing="0" border="0" style="margin-bottom:12px;">
<tr><td style="background:#ffffff;border-radius:8px;border:1px solid #e8e8e8;padding:16px 20px;">
  <a href="{url}" style="color:#1a1a2e;text-decoration:none;font-size:15px;font-weight:600;line-height:1.4;display:block;" target="_blank">{title}</a>
  <p style="color:#555;font-size:14px;line-height:1.6;margin:8px 0 10px 0;">{summary}</p>
  <span style="display:inline-block;background:#eef2ff;color:#4f46e5;font-size:12px;padding:2px 10px;border-radius:12px;">{source}</span>
</td></tr>
</table>'''

            sections_html += f'''<tr><td style="padding:24px 30px 8px 30px;">
  <h2 style="margin:0 0 16px 0;font-size:18px;color:#1a1a2e;font-weight:700;">{icon} {name}</h2>
  {cards_html}
</td></tr>'''

    html = f'''<!DOCTYPE html>
<html lang="zh-CN">
<head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1.0"></head>
<body style="margin:0;padding:0;background-color:#f0f2f5;font-family:-apple-system,BlinkMacSystemFont,'Segoe UI','PingFang SC','Hiragino Sans GB','Microsoft YaHei',sans-serif;">
<table width="100%" cellpadding="0" cellspacing="0" border="0" style="background-color:#f0f2f5;">
<tr><td align="center" style="padding:24px 16px;">
<table width="100%" cellpadding="0" cellspacing="0" border="0" style="max-width:640px;background-color:#ffffff;border-radius:12px;overflow:hidden;box-shadow:0 2px 12px rgba(0,0,0,0.08);">

<!-- Header -->
<tr><td style="background:linear-gradient(135deg,#1a1a2e 0%,#16213e 50%,#0f3460 100%);padding:32px 30px;text-align:center;">
  <h1 style="margin:0;color:#ffffff;font-size:22px;font-weight:700;letter-spacing:1px;">AI / ç§‘æŠ€æ–°é—»æ—¥æŠ¥</h1>
  <p style="margin:10px 0 0 0;color:rgba(255,255,255,0.75);font-size:14px;">{date} &nbsp;|&nbsp; {time_window}</p>
</td></tr>

<!-- News Sections -->
{sections_html}

<!-- Footer -->
<tr><td style="padding:20px 30px;border-top:1px solid #eee;text-align:center;">
  <p style="margin:0;color:#999;font-size:12px;">ç”± AI News Assistant è‡ªåŠ¨ç”Ÿæˆ &nbsp;&middot;&nbsp; Powered by Claude</p>
</td></tr>

</table>
</td></tr>
</table>
</body>
</html>'''

    return html

if __name__ == "__main__":
    anthropic_key = os.environ.get("ANTHROPIC_API_KEY")

    if not anthropic_key:
        print("Error: ANTHROPIC_API_KEY environment variable not set")
        exit(1)

    news_data = fetch_news(anthropic_key)
    print(json.dumps(news_data, ensure_ascii=False, indent=2))
